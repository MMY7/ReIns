---
title: "Using the ReIns package"
author: "Tom Reynkens"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction


The ReIns package contains functions and datasets of the book "Reinsurance: Actuarial and Statistical Aspects" (2015) of Albrecher, Beirlant and Teugels.

It contains implementations of

* Basic extreme value theory (EVT) estimators and graphical methods as described in "Statistics of Extremes: Theory and Applications" (2004) of Beirlant, Goegebeur, Segers and Teugels.

* EVT estimators and graphical methods adapted for censored and/or truncated data.

* Splicing of mixed Erlang distributions with EVT distributions (Pareto, GPD).

* VaR, expected shortfall and excess-loss premium estimates.

This vignette describes how to use the most important functions of the package.
We split this in several sections: *[datasets](#datasets), [graphical methods](#graphical-methods), [estimators of the extreme value index](#estimators-of-the-evi), [estimators of quantiles and return periods](#estimators-of-quantiles-and-return-periods), [splicing](#splicing)* and *[risk measures](#risk-measures)*.


# Datasets

Three datasets are available: **Norwegian fire insurance data** (`norwegianfire`), **SOA group medical insurance data** (`soa`) and **Secura Re automobile reinsurance data** (`secura`). These datasets were already discussed in Beirlant et al. (2004).

The illustrations will be done using the Norwegian Fire insurance dataset which contains fire insurance claims for a Norwegian insurance company for the period 1972 to 1992. The sizes of the fire insurance claims are expressed in 1000 NOK.

```{r, fig.width=5, fig.height=3.5, fig.align='center'}
library("ReIns")

data("norwegianfire")

# Claim year
year <- norwegianfire$year+1900

# Claim size
size <- norwegianfire$size

# Plot norwegian fire insurance data per year
plot(year, size, xlab="Year", ylab="Size")
```

# Graphical methods

QQ-plots and their derivative plots are an essential part of extreme value theory. We focus on three important types: the Exponential QQ-plot, Pareto QQ-plot and log-normal QQ-plot.

## Exponential QQ-plot

The **exponential QQ-plot** can be easily drawn using `ExpQQ`. Its derivative plot, also dubbed **mean excess plot** is key in determining what type of distribution the data comes from. The mean excess values $e_{k,n}$ are plotted using `MeanExcess` and one has the choice to plot them versus the order statistics $X_{n-k,n}$ (`k=FALSE`) or versus the number of exceedances $k$ (`k=TRUE`).

In this case we see that the mean-excess plot is more or less linearly increasing as a function of  $X_{n-k,n}$ which indicates that the data may come from a Pareto distribution. The exponential QQ-plot is not linear at all but concave which reinforces the conclusion drawn from the mean excess plot.

```{r, fig.width=5, fig.height=3.5, fig.align='center'}

# Exponential QQ-plot
ExpQQ(size)


# Mean excess plot with X_{n-k,n}
MeanExcess(size)

# Mean excess plot with k
MeanExcess(size, k=TRUE)
```

## Pareto QQ-plot
Taking the logarithm of Pareto distributed data gives exponentially distributed data, so the **Pareto QQ-plot** and
the exponential QQ-plot are closely related. Using the commands `ParetoQQ` and `ParetoQQ_der`, the Pareto QQ-plot and its derivative plot can be drawn. Note that these derivatives are nothing more than the Hill estimates.

The Pareto QQ-plot is now linear which indicates that the Pareto distribution is suitable. The derivative plots can be used to estimate the tail index $\gamma=1/\alpha$ of the Pareto distribution (cf. Hill estimator).
```{r, fig.width=5, fig.height=3.5, fig.align='center'}

# Pareto QQ-plot
ParetoQQ(size)


# Derivative plot with log X_{n-k,n}
ParetoQQ_der(size)

# Derivative plot with k
ParetoQQ_der(size, k=TRUE)
```


## Log-normal QQ-plot
Finally, one can also consider the **log-normal QQ-plot** (`LognormalQQ`) and its derivative plot (`LognormalQQ_der`).
It is clear that a log-normal distribution is not suitable for this data.


```{r, fig.width=5, fig.height=3.5, fig.align='center'}

# Log-normal QQ-plot
LognormalQQ(size)


# Derivative plot with log X_{n-k,n}
LognormalQQ_der(size)

# Derivative plot with k
LognormalQQ_der(size, k=TRUE)
```

# Estimators of the EVI

## Estimators of $\gamma>0$
The most famous estimator for the EVI $\gamma$ is the **Hill estimator** which can be obtained by fitting the Pareto distribution to the relative excesses $X/X_{n-k,n}$ using Maximum Likelihood Estimation (MLE). The typical Hill plot can be made using `Hill`.

The bias of the Hill estimator can be problematic so one can consider a **bias-reduced estimator** which uses a regression type approach (`Hill.2oQV`). An other solution is to use the **EPD estimator** (`EPD`) which fits the extended Pareto distribution instead of the ordinary Pareto distribution to the relative excesses.

Using these bias-reduced estimators can give an idea about a good choice for $k$. Suitable choices of $k$ are values where the two plots intersect and which are not too low (otherwise the variance is too high). This yields an estimate for $\gamma$ around 0.75 (and $k$ around 3000).


```{r, fig.width=5, fig.height=3.5, fig.align='center'}

# Hill plot
H <- Hill(size, plot=TRUE, col="blue")

# Add EPD estimator
EPD(size, add=TRUE, col="orange", lty=2)

legend("bottomright",c("Hill","EPD"), col=c("blue","orange"), lty=1:2)
```

## General estimators
The previous estimators can only be used when $\gamma$ is strictly positive. Therefore, the **generalised QQ-plot** was proposed. This QQ-plot is a generalisation of the Pareto QQ-plot and can also have negative slopes. The function `genQQ` needs the Hill estimates as input.

We see that the generalised QQ-plot is strictly increasing which indicates a strictly positive $\gamma$.

```{r, fig.width=5, fig.height=3.5, fig.align='center'}

# Generalised QQ-plot
genQQ(size, gamma=H$gamma)
```


The **generalised Hill estimator** (`genHill`) can then be defined which is an estimator for the slope of the generalised QQ-plot.
Alternatively, one can also consider the **moment estimator** (`Moment`) and the **Peaks-Over-Threshold estimator** (`GPDmle`) which fits the Generalised Pareto Distribution (GPD) to the excesses $X-X_{n-k,n}$ using Maximum Likelihood Estimation (MLE). The POT can however be very time consuming on large datasets!

The generalised Hill estimator and the moment estimator indicate that values for $\gamma$ around 0.75 are indeed suitable.

```{r, fig.width=5, fig.height=3.5, fig.align='center'}

# Generalised Hill estimator
GH <- genHill(size, gamma=H$gamma, plot=TRUE, col="blue", ylim=c(0.5,0.8))

# Moment estimator
M <- Moment(size, add=TRUE, lty=2)

legend("bottomright",c("genHill","Moment"), col=c("blue","black"), lty=1:2)
```

# Estimators of quantiles and return periods
The previously discussed estimators can be used to estimate large quantiles or small exceedance probabilities and corresponding high return periods.

## Estimators of quantiles
We can for example estimate the 99.5% quantile using Hill estimates (`Quant`) or using generalised Hill estimates (`QuantGH`), GPD estimates (`QuantGPD`) and moment estimates (`QuantMOM`).

All three estimators (we exclude the GPD estimator again) suggest a 99.5\% VaR value around 35 000 000 NOK.
```{r, fig.width=5, fig.height=3.5, fig.align='center'}

p <- 0.005

# Estimates for 99.5% VaR
Quant(size, gamma=H$gamma, p=p, plot=TRUE, col="blue", ylim=c(0,10^5))



# Estimates for 99.5% VaR
QuantGH(size, gamma=GH$gamma, p=p, plot=TRUE, col="blue", ylim=c(0,10^5))

QuantMOM(size, gamma=M$gamma, p=p, add=TRUE, lty=2)

legend("topright",c("genHill","Moment"), col=c("blue","black"), lty=1:2)
```

## Estimators of return periods
Estimating the return period of the value 100 000 000 NOK using the same three estimators (using `Return`, `ReturnGH` and `returnMOM`) gives an estimate around 800 (claims).

```{r, fig.width=5, fig.height=3.5, fig.align='center'}

q <- 10^5

# Estimates for return period
Return(size, gamma=H$gamma, q=q, plot=TRUE, col="blue", ylim=c(0,1200))



# Estimates for return period
ReturnGH(size, gamma=GH$gamma, q=q, plot=TRUE, col="blue", ylim=c(0,1200))

ReturnMOM(size, gamma=M$gamma, q=q, add=TRUE, lty=2)

legend("bottomright",c("genHill","Moment"), col=c("blue","black"), lty=1:2)
```

# Splicing

## Fitting a splicing distribution

The previous sections dealt with fitting a suitable distribution for the tail of the data. One usually
wants a fit for the whole distribution. We therefore propose the **splicing** of a Mixed Erlang (ME) distribution (body)
and an extreme value distribution, Pareto or GPD, for the tail. The method can possibly be adapted for truncation and/or censoring. We consider three possible fitting procedures:  
1. `SpliceFitPareto`: splicing of ME and Pareto distribution(s), possibly adapted for (upper) truncation.  
2. `SpliceFitGPD`: splicing of ME and GPD's, this cannot handle (upper) truncation.   
3. `SpliceFitcHill`: splicing of ME and a Pareto distribution adapted for right- or interval-censoring.  


At first, one has to determine (a) suitable splicing point(s).
We do this using the mean excess plot. Linear upward pieces indicate that the Pareto distribution is suitable, linear downward pieces suggest a truncated Pareto distribution.

```{r, fig.width=5, fig.height=3.5, fig.align='center'}
# Mean-excess plot
MeanExcess(size)

# Add vertical line at 50% and 99.6% quantiles of the data
abline(v=quantile(size, c(0.5,0.996)))
```

For the Norwegian fire insurance data, we choose splicing points at the 50\% and 99.6\% quantile.
This means that we the spliced distribution is a ME distribution between 0 and the first splicing point, a Pareto distribution between the first and second splicing point and another Pareto distribution after the second splicing point.

Using `SpliceFitPareto` we can fit this splicing distribution. This can take some time so we create a `SpliceFit` object using the obtained parameters to use in the remainder. A `summary` method is available for these objects which summarises the splicing distribution.

```{r, eval=FALSE}

# Splicing of Mixed Erlang (ME) and 2 Pareto pieces
# Use 3 as initial value for M
spliceFit <- SpliceFitPareto(size, const=c(0.5,0.996), M=3)
```

```{r}
# Create MEfit object
mefit <- MEfit(p=c(0.59,0.41), shape=c(39,58), theta=16.19, M=2)

# Create EVTfit object
evtfit <- EVTfit(gamma=c(0.80,0.64), endpoint=c(39096,Inf))

# Create SpliceFit object
splicefit <- SpliceFit(const=c(0.5,0.996), trunclower=0, t=c(1020,39096), type=c("ME","tPa","Pa"),
                       MEfit=mefit, EVTfit=evtfit)

# Show summary
summary(splicefit)
```

## Checking adequacy of fitted splicing distribution

To see how well the splicing distribution fits the data, we use 2 tools:  
1. `SpliceECDF`: plot of the fitted survival function and the empirical survival function with confidence bounds.  
2. `SplicePP`: plot of fitted survival function vs. empirical survival function. The plot with minus-log scales is most informative for the tails.

We see that the fitted splicing distribution approximates the empirical distribution quite well.

```{r, fig.width=5, fig.height=3.5, fig.align='center'}
# Points to look at
x <- seq(0, 5*10^5, 10^2)

# Plot of fitted survival function
# and empirical survival function
SpliceECDF(x, size, splicefit, ylim=c(0,0.1))

# PP-plot with fitted survival function
# and empirical survival function 
SplicePP(x, size, splicefit)

# PP-plot with log-scales
SplicePP(x, size, splicefit, log=TRUE)
```

# Risk measures

Using the fitted splicing distribution, one can compute estimates for excess-loss premiums, Value-at-Risk (VaR) and
Expected Shortfall (ES). 


## Excess-loss premiums
To estimate the **premiums of an excess-loss insurance** (with retention $M$), one can use `ExcessSplice`. It is also possible to add a limit to the insurance (e.g. $L=2M$).
```{r, fig.width=5, fig.height=3.5, fig.align='center'}
# Sequence of retentions
M <- seq(0, 10^6, 10^2)

# Premiums
e <- ExcessSplice(M, splicefit=splicefit)

# Compute premiums of excess-loss insurance min{(X-M)+,L}
e2 <- ExcessSplice(M, L=2*M, splicefit=splicefit)


# Plot premiums
plot(M, e, type="l", xlab="M", ylab="I(M)-I(M+L)", ylim=c(0,10^3))
lines(M, e2, lty=2)
legend("topright",c(expression("L"==infinity),expression("L"==2*"M")), lty=1:2, lwd=2)
```


## Value-at-Risk
A commonly used risk measure is the **Value-at-Risk** (`VaR`). This is nothing more than the quantiles $Q(1-p)$ of a distribution.
```{r, fig.width=5, fig.height=3.5, fig.align='center'}

# Take small values for p
p <- seq(0, 0.01, 0.0001)

# VaR
VaR <- VaR(p, splicefit)

# Plot VaR
plot(p, VaR, xlab="p", ylab=expression(VaR[p]), type="l")
```


## Expected shortfall
In recent years, the **Expected Shortfall** (`ES`) is gaining importance. It is the conditional expectation of the data
above a certain VaR. It is therefore always a larger than the corresponding VaR.
```{r, fig.width=5, fig.height=3.5, fig.align='center'}
# Small values for p
p <- seq(0.0001, 0.01, 0.0001)

# ES
es <- ES(p, splicefit)

# Plot ES
plot(p, es, xlab="p", ylab=expression(ES[p]), type="l")
```


